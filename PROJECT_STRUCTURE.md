# ğŸ“ Structure du Projet - Guide Complet

## ğŸ¯ Vue d'ensemble

Le projet est organisÃ© en **2 modules autonomes** qui remplacent et complÃ¨tent le brief original :

```
Brief_Terraform_2/
â”œâ”€â”€ terraform_pipeline/     # âš™ï¸ Infrastructure Azure
â””â”€â”€ data_pipeline/          # ğŸš€ Pipeline de donnÃ©es (autonome)
```

> âœ… **Note**: Le code original a Ã©tÃ© migrÃ© et amÃ©liorÃ© dans `data_pipeline/`.

---

## ğŸ“¦ terraform_pipeline

**RÃ´le**: DÃ©ployer l'infrastructure Azure via Infrastructure as Code.

### Structure

```
terraform_pipeline/
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â””â”€â”€ storage/              # Module rÃ©utilisable Storage Account
â”‚   â”œâ”€â”€ environments/
â”‚   â”‚   â”œâ”€â”€ dev.tfvars            # Config dÃ©veloppement
â”‚   â”‚   â”œâ”€â”€ rec.tfvars            # Config recette
â”‚   â”‚   â”œâ”€â”€ prod.tfvars           # Config production
â”‚   â”‚   â””â”€â”€ secrets.tfvars        # Secrets (gitignore)
â”‚   â”œâ”€â”€ main.tf                   # Ressources Azure principales
â”‚   â”œâ”€â”€ variables.tf               # Variables
â”‚   â”œâ”€â”€ outputs.tf                 # Outputs
â”‚   â””â”€â”€ providers.tf               # Providers Terraform
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile                 # Image Terraform + Azure CLI
â”‚   â””â”€â”€ entrypoint.sh              # Script d'entrÃ©e
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ windows/                   # Scripts PowerShell
â”‚   â”‚   â”œâ”€â”€ docker/               # Gestion Docker
â”‚   â”‚   â””â”€â”€ terraform/             # Gestion Terraform
â”‚   â””â”€â”€ linux/                     # Scripts Bash
â”‚       â”œâ”€â”€ docker/
â”‚       â””â”€â”€ terraform/
â””â”€â”€ docs/                          # Documentation complÃ¨te
```

### FonctionnalitÃ©s

- âœ… DÃ©ploiement multi-environnements (dev/rec/prod)
- âœ… Module Storage rÃ©utilisable
- âœ… Support Resource Group existant
- âœ… Scripts organisÃ©s par plateforme et fonction
- âœ… Documentation complÃ¨te

---

## ğŸš€ data_pipeline

**RÃ´le**: ExÃ©cuter les pipelines de donnÃ©es NYC Taxi (projet autonome).

### Structure

```
data_pipeline/
â”œâ”€â”€ pipelines/                     # Code Python des pipelines
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â””â”€â”€ download.py           # Pipeline 1: Download
â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â””â”€â”€ load_duckdb.py        # Pipeline 2: Load
â”‚   â””â”€â”€ transformation/
â”‚       â””â”€â”€ transform.py           # Pipeline 3: Transform
â”œâ”€â”€ utils/                         # Utilitaires Python
â”‚   â”œâ”€â”€ database.py                # Connexions PostgreSQL/DuckDB
â”‚   â”œâ”€â”€ download_helper.py         # TÃ©lÃ©chargement fichiers
â”‚   â””â”€â”€ parquet_utils.py           # Utilitaires Parquet
â”œâ”€â”€ sql/                           # Scripts SQL
â”‚   â”œâ”€â”€ create_staging_table.sql
â”‚   â”œâ”€â”€ insert_to.sql
â”‚   â””â”€â”€ transformations.sql
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile                 # Image multi-stage avec uv
â”‚   â”œâ”€â”€ entrypoint.sh              # Script d'entrÃ©e
â”‚   â””â”€â”€ docker-compose.yml         # Orchestration locale
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ windows/docker/            # Scripts PowerShell
â”‚   â””â”€â”€ linux/docker/              # Scripts Bash
â”œâ”€â”€ docs/                          # Documentation
â”œâ”€â”€ main.py                        # Point d'entrÃ©e
â”œâ”€â”€ pyproject.toml                 # DÃ©pendances (uv)
â””â”€â”€ uv.lock                        # Lock file
```

### FonctionnalitÃ©s

- âœ… **Autonome** : Contient tout le code Python nÃ©cessaire
- âœ… **Mode local** : Test avec Ã©mulateurs (Azurite, PostgreSQL)
- âœ… **Mode Azure** : Utilise les ressources crÃ©Ã©es par Terraform
- âœ… **Gestion des dÃ©pendances** : Utilise `uv` comme le brief original
- âœ… **Scripts organisÃ©s** : Windows/Linux sÃ©parÃ©s

---

## ğŸ”„ Workflow d'utilisation

### Ordre d'exÃ©cution

```
1. terraform_pipeline
   â””â”€â–º DÃ©ployer l'infrastructure Azure
       â”œâ”€â”€ Storage Account
       â”œâ”€â”€ Container Registry (ACR)
       â”œâ”€â”€ Cosmos DB PostgreSQL
       â””â”€â”€ Container Apps

2. data_pipeline
   â””â”€â–º Builder l'image Docker
       â””â”€â–º Push vers ACR

3. terraform_pipeline
   â””â”€â–º Finaliser le dÃ©ploiement
       â””â”€â–º Container App dÃ©marre automatiquement

4. (Optionnel) data_pipeline
   â””â”€â–º ExÃ©cuter manuellement le pipeline
```

Voir [WORKFLOW.md](./WORKFLOW.md) pour les dÃ©tails.

---

## ğŸ”§ Modules Terraform

### Module Storage

**Emplacement**: `terraform_pipeline/terraform/modules/storage/`

**Usage**:
```hcl
module "storage" {
  source = "./modules/storage"
  
  resource_group_name      = local.resource_group_name
  location                 = local.resource_group_location
  storage_account_name     = "st${var.project_name}${random_string.suffix.result}"
  account_tier             = "Standard"
  account_replication_type = "LRS"
  containers               = ["raw", "processed"]
  
  tags = var.tags
}
```

### Modules non nÃ©cessaires

| Module | NÃ©cessaire ? | Raison |
|--------|--------------|--------|
| **VM** | âŒ Non | Le Brief utilise Container Apps |
| **WebApp** | âŒ Non | Le Brief utilise Container Apps |

**Conclusion**: Seul le module Storage est nÃ©cessaire. Les autres ressources sont spÃ©cifiques au projet.

---

## ğŸ“Š Utiliser un Resource Group existant

Si tu as dÃ©jÃ  un Resource Group Azure :

```hcl
# Dans environments/dev.tfvars
use_existing_resource_group = true
existing_resource_group_name = "mon-rg-existant"
```

Terraform utilisera ce Resource Group au lieu d'en crÃ©er un nouveau.

---

## ğŸ†š FonctionnalitÃ©s de data_pipeline

| Aspect | data_pipeline |
|--------|--------------|
| **Code Python** | âœ… Complet et autonome |
| **Dockerfile** | âœ… Multi-stage avec uv |
| **DÃ©pendances** | âœ… pyproject.toml + uv.lock |
| **Scripts** | âœ… Windows/Linux organisÃ©s |
| **Documentation** | âœ… ComplÃ¨te dans docs/ |
| **Mode local** | âœ… Avec Ã©mulateurs (Azurite, PostgreSQL) |
| **Mode Azure** | âœ… Avec ressources Terraform |

**RÃ©sultat**: `data_pipeline` est un projet autonome prÃªt pour le dÃ©ploiement.

---

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| [WORKFLOW.md](./WORKFLOW.md) | Guide d'utilisation complet |
| [terraform_pipeline/docs/](./terraform_pipeline/docs/) | Documentation Terraform |
| [data_pipeline/docs/](./data_pipeline/docs/) | Documentation Data Pipeline |

---

## âœ… Avantages de cette structure

1. **SÃ©paration claire** : Infrastructure vs Pipeline de donnÃ©es
2. **Autonomie** : Chaque projet peut fonctionner indÃ©pendamment
3. **RÃ©utilisabilitÃ©** : Module Storage rÃ©utilisable
4. **Organisation** : Scripts organisÃ©s par plateforme et fonction
5. **Documentation** : Documentation complÃ¨te pour chaque module

---

## ğŸš€ Prochaines Ã©tapes

1. Lire [WORKFLOW.md](./WORKFLOW.md) pour comprendre l'ordre d'utilisation
2. Suivre le [Getting Started Terraform](./terraform_pipeline/docs/getting-started.md)
3. Tester en local avec [data_pipeline](./data_pipeline/docs/local-mode.md)
