# ğŸš€ Data Pipeline - NYC Taxi

Pipeline de donnÃ©es pour tÃ©lÃ©charger, charger et transformer les donnÃ©es NYC Taxi.

## ğŸ“‹ Vue d'ensemble

Ce module permet d'exÃ©cuter le pipeline de donnÃ©es :
- **Localement** avec des Ã©mulateurs (Azurite, PostgreSQL)
- **Sur Azure** avec les ressources crÃ©Ã©es par Terraform (via le volume partagÃ© `shared/`)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NYC TLC     â”‚      â”‚   Storage    â”‚     â”‚  PostgreSQL  â”‚
â”‚  (Source)    â”‚â”€â”€â”€â”€â–¶â”‚ (Blob/Local) â”‚â”€â”€â”€â”€â–¶â”‚   (DuckDB)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                       â”‚                    â”‚
     â”‚         PIPELINES     â”‚                    â”‚
     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
     â””â”€â”€â”‚ 1. Download â†’ 2. Load â†’ 3. Transformâ”‚â”€â”€â”€â”˜
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ DÃ©marrage rapide

### Mode Local (dÃ©veloppement)

```powershell
cd data_pipeline

# Construire l'image
.\scripts\windows\docker\build.ps1

# Lancer avec Ã©mulateurs locaux (menu interactif)
.\scripts\windows\docker\run-local.ps1
```

### Mode Azure (production)

**PrÃ©requis :** L'infrastructure doit Ãªtre dÃ©ployÃ©e via `terraform_pipeline` et le fichier `shared/.env.dev` doit exister.

```powershell
# AprÃ¨s avoir dÃ©ployÃ© l'infrastructure avec terraform_pipeline
.\scripts\windows\docker\run-azure.ps1
```

Le script dÃ©tecte automatiquement les fichiers `.env` disponibles dans `shared/`.

## ğŸ“ Structure

```
data_pipeline/
â”œâ”€â”€ pipelines/               # Code Python des pipelines
â”‚   â”œâ”€â”€ ingestion/          # Pipeline 1: Download
â”‚   â”‚   â””â”€â”€ download.py     # TÃ©lÃ©charge depuis NYC TLC â†’ Azure/Local
â”‚   â”œâ”€â”€ staging/            # Pipeline 2: Load
â”‚   â”‚   â””â”€â”€ load_duckdb.py  # Charge via DuckDB â†’ PostgreSQL
â”‚   â””â”€â”€ transformation/     # Pipeline 3: Transform
â”‚       â””â”€â”€ transform.py    # CrÃ©e le star schema
â”œâ”€â”€ utils/                   # Utilitaires Python
â”‚   â”œâ”€â”€ database.py         # Connexions PostgreSQL/DuckDB
â”‚   â”œâ”€â”€ download_helper.py  # TÃ©lÃ©chargement fichiers
â”‚   â””â”€â”€ parquet_utils.py    # Utilitaires Parquet
â”œâ”€â”€ sql/                     # Scripts SQL
â”‚   â”œâ”€â”€ create_staging_table.sql  # CrÃ©e staging_taxi_trips
â”‚   â”œâ”€â”€ insert_to.sql            # Insert via DuckDB
â”‚   â”œâ”€â”€ truncate.sql             # Nettoie la table
â”‚   â””â”€â”€ transformations.sql      # CrÃ©e DIM et FACT tables
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile           # Image multi-stage avec uv
â”‚   â”œâ”€â”€ entrypoint.sh        # Script d'entrÃ©e
â”‚   â”œâ”€â”€ docker-compose.yml   # Mode local
â”‚   â””â”€â”€ docker-compose.azure.yml  # Mode Azure
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ windows/docker/      # Scripts PowerShell
â”‚   â”‚   â”œâ”€â”€ build.ps1        # Construire l'image
â”‚   â”‚   â”œâ”€â”€ run-local.ps1    # Lancer en local
â”‚   â”‚   â”œâ”€â”€ run-azure.ps1    # Lancer sur Azure
â”‚   â”‚   â”œâ”€â”€ update.ps1       # Mettre Ã  jour l'image
â”‚   â”‚   â”œâ”€â”€ stop.ps1         # ArrÃªter les conteneurs
â”‚   â”‚   â”œâ”€â”€ remove.ps1       # Supprimer les ressources
â”‚   â”‚   â””â”€â”€ logs.ps1         # Voir les logs
â”‚   â””â”€â”€ linux/docker/        # Scripts Bash (mÃªmes fonctionnalitÃ©s)
â”œâ”€â”€ docs/                    # Documentation dÃ©taillÃ©e
â”œâ”€â”€ main.py                  # Point d'entrÃ©e
â”œâ”€â”€ pyproject.toml           # DÃ©pendances (uv)
â””â”€â”€ uv.lock                  # Lock file des dÃ©pendances
```

## ğŸ“Š Pipelines et Tables

### Pipeline 1 : Download

TÃ©lÃ©charge les fichiers Parquet depuis NYC TLC.

| Mode | Destination |
|------|-------------|
| Local | `data/raw/` (disque local) |
| Azure | Azure Blob Storage (`raw/`) + `data/raw/` (local) |

### Pipeline 2 : Load

Charge les donnÃ©es dans PostgreSQL via DuckDB.

| Source | Destination |
|--------|-------------|
| `data/raw/*.parquet` | `staging_taxi_trips` (PostgreSQL) |

### Pipeline 3 : Transform

CrÃ©e le modÃ¨le en Ã©toile (Star Schema).

| Table | Type | Description |
|-------|------|-------------|
| `staging_taxi_trips` | Staging | DonnÃ©es brutes |
| `dim_datetime` | Dimension | Dates, heures, pÃ©riodes |
| `dim_location` | Dimension | Zones gÃ©ographiques NYC |
| `dim_payment` | Dimension | Types de paiement |
| `dim_vendor` | Dimension | Fournisseurs (CMT, VeriFone) |
| `dim_rate_code` | Dimension | Codes tarifaires (bonus) |
| `fact_trips` | Fait | MÃ©triques des trajets |

## ğŸ”§ Modes d'exÃ©cution

### Mode Local

Utilise des Ã©mulateurs Docker :
- **Azurite** : Ã‰mulateur Azure Storage (port 10000)
- **PostgreSQL** : Base de donnÃ©es locale (port 5432)
- **PgAdmin** : Interface web (port 5050, optionnel)

```powershell
# Lancer avec menu interactif
.\scripts\windows\docker\run-local.ps1

# Lancer avec PgAdmin (option 3 du menu)
```

### Mode Azure

Utilise les ressources dÃ©ployÃ©es par Terraform via le volume partagÃ© :

```
shared/
â”œâ”€â”€ .env.dev    # GÃ©nÃ©rÃ© par terraform apply dev
â”œâ”€â”€ .env.rec    # GÃ©nÃ©rÃ© par terraform apply rec
â””â”€â”€ .env.prod   # GÃ©nÃ©rÃ© par terraform apply prod
```

Le fichier `.env` contient :
- `AZURE_STORAGE_CONNECTION_STRING` : Connexion Azure Blob
- `POSTGRES_HOST`, `POSTGRES_PASSWORD` : Connexion PostgreSQL
- `ACR_LOGIN_SERVER`, `ACR_PASSWORD` : Connexion Container Registry
- `START_DATE`, `END_DATE` : PÃ©riode du pipeline

## ğŸ› ï¸ Scripts disponibles

### Windows (PowerShell)

| Script | Description |
|--------|-------------|
| `build.ps1` | Construire l'image Docker (menu interactif) |
| `run-local.ps1` | Lancer en mode local |
| `run-azure.ps1` | Lancer en mode Azure |
| `update.ps1` | Mettre Ã  jour l'image |
| `stop.ps1` | ArrÃªter les conteneurs |
| `remove.ps1` | Supprimer conteneurs/volumes/images |
| `logs.ps1` | Voir les logs |

### Linux (Bash)

MÃªmes fonctionnalitÃ©s dans `scripts/linux/docker/`.

```bash
./scripts/linux/docker/build.sh
./scripts/linux/docker/run-local.sh
./scripts/linux/docker/run-azure.sh
./scripts/linux/docker/stop.sh
```

## ğŸ”— IntÃ©gration avec Terraform

### Volume partagÃ©

Le dossier `shared/` Ã  la racine du projet sert de pont entre les deux modules :

1. **terraform_pipeline** gÃ©nÃ¨re les fichiers `.env`:
   - `apply dev` â†’ crÃ©e `shared/.env.dev`
   - `destroy dev` â†’ supprime `shared/.env.dev`

2. **data_pipeline** lit les fichiers `.env`:
   - `run-azure.sh` â†’ utilise `shared/.env.dev`

### Workflow complet

```bash
# 1. DÃ©ployer l'infrastructure (gÃ©nÃ¨re shared/.env.dev)
cd terraform_pipeline
./scripts/linux/docker/run.sh
apply dev
exit

# 2. ExÃ©cuter le pipeline (utilise shared/.env.dev)
cd ../data_pipeline
./scripts/linux/docker/run-azure.sh
```

## ğŸ“š Documentation

- [Getting Started](./docs/getting-started.md) - Premiers pas
- [Mode Local](./docs/local-mode.md) - Utilisation locale
- [Mode Azure](./docs/azure-mode.md) - Utilisation Azure
- [Scripts](./docs/scripts.md) - DÃ©tail des scripts
- [Troubleshooting](./docs/troubleshooting.md) - RÃ©solution de problÃ¨mes

## ğŸ”— Liens

- [Terraform Pipeline](../terraform_pipeline/) - Infrastructure Azure
- [Guide DÃ©butant](../GUIDE_DEBUTANT.md) - Guide pas Ã  pas complet
- [Brief](../brief-terraform/BRIEF.md) - Instructions originales
