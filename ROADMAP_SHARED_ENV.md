# Roadmap : Volume Partagé entre Terraform et Data Pipeline

## Objectif
Permettre à `terraform_pipeline` de générer automatiquement un fichier `.env` 
que `data_pipeline` peut consommer, via un volume Docker partagé.

---

## Architecture Cible

```
Brief_Terraform_2/
├── shared/                          ← NOUVEAU: Dossier partagé
│   └── .env.azure                   ← Généré par Terraform après apply
│
├── terraform_pipeline/
│   ├── docker/
│   │   └── ...
│   ├── scripts/
│   │   └── terraform/
│   │       ├── apply.sh             ← NOUVEAU: Wrapper apply + génère .env
│   │       └── destroy.sh           ← NOUVEAU: Wrapper destroy + supprime .env
│   └── terraform/
│       └── outputs.tf               ← À ENRICHIR: outputs pour .env
│
└── data_pipeline/
    ├── docker/
    │   └── docker-compose.yml       ← À MODIFIER: monte shared/
    └── .env                         ← Symlink ou copie de shared/.env.azure
```

---

## Tâches à Implémenter

### Phase 1 : Structure du volume partagé
- [x] 1.1 Créer le dossier `shared/` à la racine du projet
- [x] 1.2 Ajouter `shared/.gitkeep` (garder le dossier dans git)
- [x] 1.3 Ajouter `shared/.env.azure` au `.gitignore` (ne pas commiter les secrets)

### Phase 2 : Terraform Pipeline - Génération du .env
- [x] 2.1 Enrichir `outputs.tf` avec toutes les valeurs nécessaires :
  - `storage_connection_string` (sensitive)
  - `postgres_host`
  - `postgres_password` (sensitive)
  - `acr_login_server`
  - `acr_admin_username`
  - `acr_admin_password` (sensitive)
- [x] 2.2 Créer script `terraform/scripts/generate-env.sh` :
  - Lit les outputs Terraform
  - Génère `/workspace/shared/.env.{env}`
- [x] 2.3 Créer script `terraform/scripts/apply.sh` :
  - Exécute `terraform apply`
  - Appelle `generate-env.sh` si succès
- [x] 2.4 Créer script `terraform/scripts/destroy.sh` :
  - Exécute `terraform destroy`
  - Supprime `/workspace/shared/.env.{env}` si succès
- [x] 2.5 Modifier `run.ps1` / `run.sh` pour monter `shared/` :
  - `-v "$SharedDir:/workspace/shared"`
- [x] 2.6 Mettre à jour `entrypoint.sh` avec nouvelles commandes

### Phase 3 : Data Pipeline - Consommation du .env
- [x] 3.1 Modifier `docker-compose.yml` pour monter `shared/` :
  - `- ../../shared:/app/shared:ro`
- [x] 3.2 Créer `docker-compose.azure.yml` pour le mode Azure :
  - Utilise `env_file` pour charger les variables depuis shared/
- [x] 3.3 Le code Python n'a pas besoin de changement :
  - Docker Compose injecte les variables d'environnement
  - `load_dotenv()` charge le `.env` local pour le développement

### Phase 4 : Menu et Documentation
- [x] 4.1 Mettre à jour `entrypoint.sh` avec nouvelles commandes :
  ```
  Commandes simplifiées:
    plan [env]     - Prévisualiser
    apply [env]    - Déployer + générer .env
    destroy [env]  - Détruire + supprimer .env
    genenv [env]   - Régénérer le .env
  ```
- [x] 4.2 Améliorer scripts `data_pipeline` (build, stop, run-local, run-azure)
  - Docker checks, menus interactifs, couleurs
  - `run-azure` utilise les fichiers `.env.{env}` générés par Terraform
- [x] 4.3 Mettre à jour `GUIDE_DEBUTANT.md`
- [x] 4.4 Mettre à jour `README.md` des deux projets

### Phase 5 : Tests et Validation
- [x] 5.1 Tester le cycle complet :
  - `terraform apply` → `.env.dev` généré ✅
  - `data_pipeline` lit les bonnes valeurs ✅
  - `terraform destroy` → `.env.dev` supprimé
- [x] 5.2 Tester la re-création après destroy
- [x] 5.3 Valider que les secrets ne sont pas exposés dans les logs

---

## Format du fichier `.env.azure` généré

```env
# =============================================================================
# Azure Environment - Auto-generated by Terraform
# DO NOT EDIT - This file is regenerated on each 'terraform apply'
# Generated: 2026-01-14T15:30:00Z
# Environment: dev
# =============================================================================

# Azure Storage
AZURE_STORAGE_CONNECTION_STRING=DefaultEndpointsProtocol=https;AccountName=stnyctaxidev6wt9e9;AccountKey=xxx;EndpointSuffix=core.windows.net
AZURE_CONTAINER_NAME=raw

# PostgreSQL (Cosmos DB)
POSTGRES_HOST=c-nyctaxi-dev-6wt9e9.postgres.cosmos.azure.com
POSTGRES_PORT=5432
POSTGRES_DB=citus
POSTGRES_USER=citus
POSTGRES_PASSWORD=xxx
POSTGRES_SSL_MODE=require

# Azure Container Registry
ACR_LOGIN_SERVER=acrnyctaxidev6wt9e9.azurecr.io
ACR_USERNAME=acrnyctaxidev6wt9e9
ACR_PASSWORD=xxx

# Metadata
TERRAFORM_ENVIRONMENT=dev
TERRAFORM_WORKSPACE=default
```

---

## Montage des volumes

### Terraform Container (run.ps1 / run.sh)
```bash
docker run ... \
  -v "$TerraformDir:/workspace/terraform" \
  -v "$SharedDir:/workspace/shared" \           # NOUVEAU
  -v "$DataPipelineDir:/workspace/data_pipeline:ro" \
  ...
```

### Data Pipeline Container (docker-compose.yml)
```yaml
services:
  pipeline:
    volumes:
      - ./data:/app/data
      - ../../shared:/app/shared:ro              # NOUVEAU (read-only)
```

---

## Sécurité

1. **`.gitignore`** : `shared/.env.azure` ne doit JAMAIS être commité
2. **Permissions** : data_pipeline monte en read-only (`:ro`)
3. **Logs** : Les scripts ne doivent pas afficher les valeurs sensibles
4. **Nettoyage** : `destroy.sh` supprime le fichier pour éviter les fuites

---

## Ordre d'implémentation recommandé

1. ✅ Phase 1 (structure) - 5 min
2. ✅ Phase 2 (terraform) - 30 min
3. ✅ Phase 3 (data_pipeline) - 20 min
4. ✅ Phase 4 (documentation) - 15 min
5. ✅ Phase 5 (tests) - 15 min

**Total estimé : ~1h30**

---

## Questions ouvertes

1. **Environnements multiples** : Un seul `.env.azure` ou un par environnement ?
   - Option A : `shared/.env.azure` (un seul, écrasé à chaque apply)
   - Option B : `shared/.env.dev`, `shared/.env.rec`, `shared/.env.prod`
   
   → **Recommandation** : Option B pour pouvoir tester plusieurs environnements

2. **Fallback** : Que faire si `.env.azure` n'existe pas ?
   - Utiliser `.env` local par défaut (mode développement)
   - Afficher un warning mais continuer

---

## Prochaine étape

Confirmez cette roadmap et je commence l'implémentation par la Phase 1.
